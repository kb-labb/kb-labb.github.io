@misc{swedish-bert,
    title={Playing with Words at the National Library of Sweden -- Making a Swedish BERT},
    author={Martin Malmsten and Love Börjeson and Chris Haffenden},
    year={2020},
    eprint={2007.01658},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{bert,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  archivePrefix = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@unpublished{rekathati,
author  = {Rekathati, Faton and Hurtado Bodell, Miriam and Magnusson, Måns},
title   = {Efficient annotation of newspaper sections},
year    = {n.d.},
note    = {unpublished},
}

@inproceedings{sentence-bert,
    title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/1908.10084",
}

@inproceedings{multilingual-sentence-bert,
    title = "Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2020",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/2004.09813",
}

@article{stsb,
   title={SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and
            Crosslingual Focused Evaluation},
   url={http://dx.doi.org/10.18653/v1/S17-2001},
   DOI={10.18653/v1/s17-2001},
   journal={Proceedings of the 11th International Workshop on Semantic Evaluation
          (SemEval-2017)},
   publisher={Association for Computational Linguistics},
   author={Cer, Daniel and Diab, Mona and Agirre, Eneko and Lopez-Gazpio, Inigo and Specia, Lucia},
   year={2017}
}

@article{superlim,
	title        = {SwedishGLUE – Towards a Swedish Test Set for Evaluating Natural Language Understanding Models},
	author       = {Adesam, Yvonne and Berdicevskis, Aleksandrs and Morger, Felix},
	year         = {2020},
	publisher    = {University of Gothenburg},
}

@article{isbister-simply,
      title={Why Not Simply Translate? A First Swedish Evaluation Benchmark for Semantic Similarity}, 
      author={Tim Isbister and Magnus Sahlgren},
      year={2020},
      eprint={2009.03116},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@proceedings{carlsson,
  title     = {Semantic Re-tuning with Contrastive Tension },
  author    = {Carlsson, Fredrik, and Gogoulou, Evangelina and Ylipää, Erik and Cuba Gyllensten, Amaru and Sahlgren, Magnus},
  publisher = {International Conference on Learning Representations, {ICLR} 2021},
  year      = {2021},
  url       = {https://openreview.net/pdf?id=Ov_sMNau-PF},
}


@InProceedings{opus,
  author = {Jörg Tiedemann},
  title = {Parallel Data, Tools and Interfaces in OPUS},
  booktitle = {Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC'12)},
  year = {2012},
  month = {may},
  date = {23-25},
  address = {Istanbul, Turkey},
  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri and Thierry Declerck and Mehmet Ugur Dogan and Bente Maegaard and Joseph Mariani and Jan Odijk and Stelios Piperidis},
  publisher = {European Language Resources Association (ELRA)},
  isbn = {978-2-9517408-7-7},
  language = {english}
 }
 
 
 @inproceedings{opensubtitles,
    title = "{O}pen{S}ubtitles2016: Extracting Large Parallel Corpora from Movie and {TV} Subtitles",
    author = {Lison, Pierre  and
      Tiedemann, J{\"o}rg},
    booktitle = "Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}'16)",
    month = may,
    year = "2016",
    address = "Portoro{\v{z}}, Slovenia",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://aclanthology.org/L16-1147",
    pages = "923--929",
    abstract = "We present a new major release of the OpenSubtitles collection of parallel corpora. The release is compiled from a large database of movie and TV subtitles and includes a total of 1689 bitexts spanning 2.6 billion sentences across 60 languages. The release also incorporates a number of enhancements in the preprocessing and alignment of the subtitles, such as the automatic correction of OCR errors and the use of meta-data to estimate the quality of each subtitle and score subtitle pairs.",
}

@inproceedings{jw300,
    title = "{JW}300: A Wide-Coverage Parallel Corpus for Low-Resource Languages",
    author = "Agi{\'c}, {\v{Z}}eljko  and
      Vuli{\'c}, Ivan",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1310",
    doi = "10.18653/v1/P19-1310",
    pages = "3204--3210",
    abstract = "Viable cross-lingual transfer critically depends on the availability of parallel texts. Shortage of such resources imposes a development and evaluation bottleneck in multilingual processing. We introduce JW300, a parallel corpus of over 300 languages with around 100 thousand parallel sentences per language pair on average. In this paper, we present the resource and showcase its utility in experiments with cross-lingual word embedding induction and multi-source part-of-speech projection.",
}

@misc{superglue,
      title={SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems}, 
      author={Alex Wang and Yada Pruksachatkun and Nikita Nangia and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
      year={2020},
      eprint={1905.00537},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{supersim,
    title = "{S}uper{S}im: a test set for word similarity and relatedness in {S}wedish",
    author = "Hengchen, Simon  and
      Tahmasebi, Nina",
    booktitle = "Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa)",
    month = may # " 31--2 " # jun,
    year = "2021",
    address = "Reykjavik, Iceland (Online)",
    publisher = {Link{\"o}ping University Electronic Press, Sweden},
    url = "https://aclanthology.org/2021.nodalida-main.27",
    pages = "268--275",
    abstract = "Language models are notoriously difficult to evaluate. We release SuperSim, a large-scale similarity and relatedness test set for Swedish built with expert human judgements. The test set is composed of 1,360 word-pairs independently judged for both relatedness and similarity by five annotators. We evaluate three different models (Word2Vec, fastText, and GloVe) trained on two separate Swedish datasets, namely the Swedish Gigaword corpus and a Swedish Wikipedia dump, to provide a baseline for future comparison. We will release the fully annotated test set, code, models, and data.",
}
