@inproceedings{koluguri2022titanet,
  title={TitaNet: Neural Model for Speaker Representation with 1D Depth-Wise Separable Convolutions and Global Context},
  author={Koluguri, Nithin Rao and Park, Taejin and Ginsburg, Boris},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={8102--8106},
  year={2022},
  organization={IEEE}
}

@misc{rekathati2023finding,
  author = {Rekathati, Faton},
  title = {The KBLab Blog: Finding Speeches in the Riksdag's Debates},
  url = {https://kb-labb.github.io/posts/2023-02-15-finding-speeches-in-the-riksdags-debates/},
  year = {2023}
}

@misc{rekathati2023rixvox,
  author = {Rekathati, Faton},
  title = {The KBLab Blog: RixVox: A Swedish Speech Corpus with 5500 Hours of Speech from Parliamentary Debates},
  url = {https://kb-labb.github.io/posts/2023-03-09-rixvox-a-swedish-speech-corpus/},
  year = {2023}
}

@mastersthesis{Nachesa1762445,
   author = {Nachesa, Maya Konstantinovna},
   institution = {Uppsala University, Department of Linguistics and Philology},
   school = {Uppsala University, Department of Linguistics and Philology},
   title = {How do voiceprints age?},
   url = {https://www.diva-portal.org/smash/record.jsf?pid=diva2:1762445},
   keywords = {Voiceprint, Speaker Emotion Recognition, Age, Speaker Verification},
   abstract = {Voiceprints, like fingerprints, are a biometric. Where fingerprints record a person's unique pattern on their finger, voiceprints record what a person's voice "sounds like", abstracting away from what the person said. They have been used in speaker recognition, including verification and identification. In other words, they have been used to ask "is this speaker who they say they are?" or "who is this speaker?", respectively. However, people age, and so do their voices. Do voiceprints age, too? That is, can a person's voice change enough that after a while, the original voiceprint can no longer be used to identify them? In this thesis, I use Swedish audio recordings from Riksdagen's (the Swedish parliament) debate speeches to test this idea. Depending on the answer, this influences how well we can search the database for previously unmarked speeches. I find that speaker verification performance decreases as the age-gap between voiceprints increases, and that it decreases more strongly after roughly five years. Additionally,Â I grouped the speakers into age groups spanning five years, and found that speaker verification has the highest performance for those for whom the initial voiceprint was recorded from 29-33 years of age. Additionally, longer input speech provides higher quality voiceprints, with performance improvements stagnating when voiceprints become longer than 30 seconds. Finally, voiceprints for men age more strongly than those for women after roughly 5 years. I also investigated how emotions are encoded in voiceprints, since this could potentially impede in speaker recognition. I found that it is possible to train a classifier to recognise emotions from voiceprints, and that this classifier does better when recognising emotions from known speakers. That is, emotions are encoded more characteristically per person as opposed to per emotion itself. As such, they are unlikely to interfere with speaker recognition. },
   year = {2023}
}